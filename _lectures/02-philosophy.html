---
title: "The Atomic Human: Philosophy"
abstract: "<p>This lecture explores the philosophical questions raised
by the development of artificial intelligence and our evolving
understanding of human cognition. We examine key philosophical concepts
related to intelligence, consciousness, and the nature of knowledge, and
how these ideas are challenged and reshaped by advances in AI. By
understanding these philosophical perspectives, we gain deeper insights
into what it means to be human in the age of artificial
intelligence.</p>"
edit_url: https://github.com/mlatcl/atomichuman/edit/gh-pages/_lamd/philosophy.md
week: 2
reveal: 02-philosophy.slides.html
ipynb: 02-philosophy.ipynb
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h1 id="introduction-the-philosophical-challenge-of-ai">Introduction:
The Philosophical Challenge of AI</h1>
<h1 id="the-great-ai-fallacy">The Great AI Fallacy</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-great-ai-fallacy.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-great-ai-fallacy.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>There is a lot of variation in the use of the term artificial
intelligence. I’m sometimes asked to define it, but depending on whether
you’re speaking to a member of the public, a fellow machine learning
researcher, or someone from the business community, the sense of the
term differs.</p>
<p>However, underlying its use I’ve detected one disturbing trend. A
trend I’m beginining to think of as “The Great AI Fallacy”.</p>
<p>The fallacy is associated with an implicit promise that is embedded
in many statements about Artificial Intelligence. Artificial
Intelligence, as it currently exists, is merely a form of automated
decision making. The implicit promise of Artificial Intelligence is that
it will be the first wave of automation where the machine adapts to the
human, rather than the human adapting to the machine.</p>
<p>How else can we explain the suspension of sensible business judgment
that is accompanying the hype surrounding AI?</p>
<p>This fallacy is particularly pernicious because there are serious
benefits to society in deploying this new wave of data-driven automated
decision making. But the AI Fallacy is causing us to suspend our
calibrated skepticism that is needed to deploy these systems safely and
efficiently.</p>
<p>The problem is compounded because many of the techniques that we’re
speaking of were originally developed in academic laboratories in
isolation from real-world deployment.</p>
<div class="figure">
<div id="jeeves-springtime-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/Jeeves_in_the_Springtime_01.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="jeeves-springtime-magnify" class="magnify"
onclick="magnifyFigure(&#39;jeeves-springtime&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="jeeves-springtime-caption" class="caption-frame">
<p>Figure: We seem to have fallen for a perspective on AI that suggests
it will adapt to our schedule, rather in the manner of a 1930s
manservant.</p>
</div>
</div>
<p>This “great AI fallacy” sets the stage for our philosophical
exploration of AI and human intelligence.</p>
<h1 id="the-nature-of-intelligence">The Nature of Intelligence</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="what-is-intelligence">What is Intelligence?</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/what-is-intelligence.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/what-is-intelligence.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>One challenge with the word intelligence is it means many different
things to different people. My own definition of intelligence is the use
of information to achieve goals more efficiently. Where information is
measured in Shannon terms, and efficiency is measured in terms of use of
resource, typically available energy or maybe time. The definition
appeals to me because it brings about a connection between the major
historic revolutions, which have been about energy, and the current
changes which focus more on information. However, the definition does
not specify the goal. Some prefer to try and incorporate the goal in
their definition of intelligence, and that goals should be somehow
emergent from intelligence. For complex tasks sub-goals are certainly
emergent, but I don’t seek to incorporate a global goal in my own
definition.</p>
<p>So where are we in terms of intelligence? There is certainly an
information revolution going on, and it is causing disruption across
many industries. But what we are saying about machine learning and
artificial inteligence has been said before in relation to the invention
of sillicon chips. I gave a version of this talk once at the BBC, and
Bill Thompson was kind enough to share with me the archive of “Silicon
Factor”, a series of three programs broadcast in 1980 exploring the
“microelectronics revolution”. There is a remarkable similarity to
everything the experts say in these programs and what experts say about
AI today. And of course, these experts were right, jobs have changed,
industry is different and we are still deep in the micro-electronics
revolution. However, these changes do not happen overnight, those
broadcasts were made nearly forty years ago. The “Fourth Industrial
Revolution” is merely a continuation of an ongoing revolution in
information, one which was triggered by the Silicon Factor, continued by
the internet and has been given further momentum by mobile
communications.</p>
<p>With a word like intelligence, we can’t just think about our own
definition of intelligence, but we should also take into account public
understanding of the word. For many people intelligence is something
specific to humans, and as a result what the term refers to evolves.
Artificial intelligence is a very emotive term, because it feels close
to us, it makes us think that computers are doing things like us. As a
result it is also a shifting definition, it comes to me “intelligence is
the stuff I can do that computers can’t”. This lends a narcissistic
element to our fascination with artificial intelligence, because it is
also a fascination with ourselves.</p>
<p>A hundred years ago <em>computers</em> were human beings, often
female, who conducted repetitive mathematical tasks for the creation of
mathematical tables such as logarithms. Our modern digital computers
were originally called <em>automatic computers</em> to reflect the fact
that the intelligence of these human operators had been automated. But
despite the efficiency with which they perform these tasks, very few
think of their mobile phones or computers as intelligent.</p>
<h2 id="cybernetics-and-the-ratio-club">Cybernetics and the Ratio
Club</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/cybernetics-ratio-club.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/cybernetics-ratio-club.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Norbert Wiener launched last century’s first wave of interest in
emulation of intelligence with his book “Cybernetics”. The great modern
success that stemmed from that work is the modern engineering discipline
of Automatic Control. The technology that allows fighter jets to fly.
These ideas came out of the Second World War, when researchers explored
the use of radar (automated sensing) and automatic computation for
decryption of military codes (automated decision making). Post war a
body of researchers, including Alan Turing, were seeing the potential
for electronic emulation of what had up until then been the preserve of
an animallian nervous system.</p>
<div class="figure">
<div id="science-holborn-viaduct-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//science-holborn-viaduct.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="science-holborn-viaduct-magnify" class="magnify"
onclick="magnifyFigure(&#39;science-holborn-viaduct&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="science-holborn-viaduct-caption" class="caption-frame">
<p>Figure: Centrifugal governor as held by “Science” on Holborn
Viaduct</p>
</div>
</div>
<p>Artificial intelligence is a badly defined term. Successful
deployments of intelligent systems are common, but normally they are
redefined to be non-intelligent. My favourite example is <a
href="https://en.wikipedia.org/wiki/Centrifugal_governor">the
Centrifugal governor</a>. Applied to the Steam Engine by Boulton and
Watt and immortalised in the arms of the statue of “Science” on the
Holborn viaduct in London, the centrifugal governor automatically
regulated the speed of a steam engine, closing the inlet valve
progressively as the engine ran faster. It did the job that an
intelligent operator used to have to do, but few today would describe it
as “artificial intelligence”.</p>
<p>The current revolution in AI is being driven by machine learning.
Machine learning is an approach to prediction which is data driven. It
is not the first approach to focus on data, the statistical sciences
have combined models with data for a number of years. But machine
learning has taken a particular focus on improving the quality of
prediction, whereas statistical sciences have traditionally focussed
more on explaination. Machine learning is giving us information
processing engines that are equivalent to the steam engines of the
industrial revolution.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> intelligence, definitions of p. 102-103, 126, 134, 140,
143, 149, 260, 264, 269, 277, 315, 358, 363.</p>
<h1 id="embodiment-and-intelligence">Embodiment and Intelligence</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="embodiment-factors">Embodiment Factors</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="embodiment-factors-table-figure" class="figure-frame">
<table>
<tr>
<td>
</td>
<td align="center">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/processor.svg" width="15%" style=" ">
</object>
</td>
<td align="center">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//human.svg" width="60%" style=" ">
</object>
</td>
</tr>
<tr>
<td>
bits/min
</td>
<td align="center">
billions
</td>
<td align="center">
2,000
</td>
</tr>
<tr>
<td>
billion <br>calculations/s
</td>
<td align="center">
~100
</td>
<td align="center">
a billion
</td>
</tr>
<tr>
<td>
embodiment
</td>
<td align="center">
20 minutes
</td>
<td align="center">
5 billion years
</td>
</tr>
</table>
</div>
<div id="embodiment-factors-table-magnify" class="magnify"
onclick="magnifyFigure(&#39;embodiment-factors-table&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="embodiment-factors-table-caption" class="caption-frame">
<p>Figure: Embodiment factors are the ratio between our ability to
compute and our ability to communicate. Relative to the machine we are
also locked in. In the table we represent embodiment as the length of
time it would take to communicate one second’s worth of computation. For
computers it is a matter of minutes, but for a human, it is a matter of
thousands of millions of years. See also “Living Together: Mind and
Machine Intelligence” <span class="citation"
data-cites="Lawrence:embodiment17">Lawrence (2017)</span></p>
</div>
</div>
<p>There is a fundamental limit placed on our intelligence based on our
ability to communicate. Claude Shannon founded the field of information
theory. The clever part of this theory is it allows us to separate our
measurement of information from what the information pertains to.<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<p>Shannon measured information in bits. One bit of information is the
amount of information I pass to you when I give you the result of a coin
toss. Shannon was also interested in the amount of information in the
English language. He estimated that on average a word in the English
language contains 12 bits of information.</p>
<p>Given typical speaking rates, that gives us an estimate of our
ability to communicate of around 100 bits per second <span
class="citation" data-cites="Reed-information98">(Reed and Durlach,
1998)</span>. Computers on the other hand can communicate much more
rapidly. Current wired network speeds are around a billion bits per
second, ten million times faster.</p>
<p>When it comes to compute though, our best estimates indicate our
computers are slower. A typical modern computer can process make around
100 billion floating-point operations per second, each floating-point
operation involves a 64 bit number. So the computer is processing around
6,400 billion bits per second.</p>
<p>It’s difficult to get similar estimates for humans, but by some
estimates the amount of compute we would require to <em>simulate</em> a
human brain is equivalent to that in the UK’s fastest computer <span
class="citation" data-cites="Ananthanarayanan-cat09">(Ananthanarayanan
et al., 2009)</span>, the MET office machine in Exeter, which in 2018
ranked as the 11th fastest computer in the world. That machine simulates
the world’s weather each morning, and then simulates the world’s climate
in the afternoon. It is a 16-petaflop machine, processing around 1,000
<em>trillion</em> bits per second.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> embodiment factor p. 13, 29, 35, 79, 87, 105, 197,
216-217, 249, 269, 353, 369.</p>
<p>The concept of embodiment challenges traditional notions of
intelligence and raises questions about the nature of consciousness and
cognition.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> embodiment factor p. 13, 29, 35, 79, 87, 105, 197,
216-217, 249, 269, 353, 369.</p>
<h1 id="the-limits-of-human-knowledge">The Limits of Human
Knowledge</h1>
<h2 id="laplaces-demon">Laplace’s Demon</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-demon.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-demon.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<iframe frameborder="0" scrolling="no" style="border:0px" src="https://books.google.co.uk/books?id=1YQPAAAAQAAJ&amp;pg=PR17-IA2&amp;output=embed" width="700" height="500">
</iframe>
<div class="figure">
<div id="laplaces-demon-cropped-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//physics/philosophicaless00lapliala_16_cropped.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="laplaces-demon-cropped-magnify" class="magnify"
onclick="magnifyFigure(&#39;laplaces-demon-cropped&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="laplaces-demon-cropped-caption" class="caption-frame">
<p>Figure: English translation of Laplace’s demon, taken from the
Philosophical Essay on probabilities <span class="citation"
data-cites="Laplace-essai14">Laplace (1814)</span> pg 3.</p>
</div>
</div>
<p>One way of viewing what Laplace is saying is that we can take “the
forces by which nature is animated” or our best
mathematical/computational abstraction of that which we would call the
<em>model</em> and combine it with the “respective situation of the
beings who compose it” which I would refer to as the <em>data</em> and
if we have an “intelligence sufficiently vast enough to submit these
data to analysis”, or sufficient <em>compute</em> then we would have a
system for which “nothing would be uncertain and the future, as the
past, would be present in its eyes”, or in other words we can make a
<em>prediction</em>. Or more succinctly put we have</p>
<center>
<span class="math display">\[
\text{model} + \text{data} \stackrel{\text{compute}}{\rightarrow}
\text{prediction}.\]</span>
</center>
<p>Laplace’s demon has been a recurring theme in science, we can also
find it in Stephen Hawking’s book <em>A Brief History of Time</em> <span
class="citation" data-cites="Hawking-history88">(<em>A brief history of
time</em>, 1988)</span>.</p>
<blockquote>
<p>If we do discover a theory of everything … it would be the ultimate
triumph of human reason-for then we would truly know the mind of God</p>
<p>Stephen Hawking in <em>A Brief History of Time</em> 1988</p>
</blockquote>
<p>But is it really that simple? Do we just need more and more accurate
models and more and more data?</p>
<p>Laplace’s demon represents the philosophical ideal of perfect
knowledge and determinism, which contrasts sharply with our current
understanding of uncertainty and complexity.</p>
<h2 id="laplaces-gremlin">Laplace’s Gremlin</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-gremlin.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-gremlin.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<blockquote>
<p>The curve described by a simple molecule of air or vapor is regulated
in a manner just as certain as the planetary orbits; the only difference
between them is that which comes from our ignorance. Probability is
relative, in part to this ignorance, in part to our knowledge. We know
that of three or greater number of events a single one ought to occur;
but nothing induces us to believe that one of them will occur rather
than the others. In this state of indecision it is impossible for us to
announce their occurrence with certainty. It is, however, probable that
one of these events, chosen at will, will not occur because we see
several cases equally possible which exclude its occurrence, while only
a single one favors it.</p>
<p>— Pierre-Simon Laplace <span class="citation"
data-cites="Laplace-essai14">(Laplace, 1814)</span>, pg 5</p>
</blockquote>
<p>The representation of ignorance through probability is the true
message of Laplace, I refer to this message as “Laplace’s gremlin”,
because it is the gremlin of uncertainty that interferes with the demon
of determinism to mean that our predictions are not deterministic.</p>
<p>Our separation of the uncertainty into the data, the model and the
computation give us three domains in which our doubts can creep into our
ability to predict. Over the last three lectures we’ve introduced some
of the basic tools we can use to unpick this uncertainty. You’ve been
introduced to, (or have yow reviewed) <em>Bayes’ rule</em>. The rule,
which is a simple consequence of the product rule of probability, is the
foundation of how we update our beliefs in the presence of new
information.</p>
<p>The real point of Laplace’s essay was that we don’t have access to
all the data, we don’t have access to a complete physical understanding,
and as the example of the Game of Life shows, even if we did have access
to both (as we do for “Conway’s universe”) we still don’t have access to
all the compute that we need to make deterministic predictions. There is
uncertainty in the system which means we can’t make precise
predictions.</p>
<p>Gremlins are imaginary creatures used as an explanation of failure in
aircraft, causing crashes. In that sense the Gremlin represents the
uncertainty that a pilot felt about what might go wrong in a plane which
might be “theoretically sound” but in practice is poorly maintained or
exposed to conditions that take it beyond its design criteria. Laplace’s
gremlin is all the things that your model, data and ability to compute
don’t account for bringing about failures in your ability to predict.
Laplace’s gremlin is the uncertainty in the system.</p>
<div class="figure">
<div id="germlins-think-its-fun-to-hurt-you-figure"
class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/gremlins-think-its-fun-to-hurt-you.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="germlins-think-its-fun-to-hurt-you-magnify" class="magnify"
onclick="magnifyFigure(&#39;germlins-think-its-fun-to-hurt-you&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="germlins-think-its-fun-to-hurt-you-caption"
class="caption-frame">
<p>Figure: Gremlins are seen as the cause of a number of challenges in
this World War II poster.</p>
</div>
</div>
<p>The concept of Laplace’s Gremlin introduces the philosophical
implications of uncertainty and probability in our understanding of the
world.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> Laplace’s demon p. 126, 134, 140, 143, 149, 260, 264, 269,
277, 315, 358, 363.</p>
<h1 id="the-philosophy-of-mind">The Philosophy of Mind</h1>
<div class="figure">
<div id="mind-is-flat-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//cognitive-science/mind-is-flat.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="mind-is-flat-magnify" class="magnify"
onclick="magnifyFigure(&#39;mind-is-flat&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mind-is-flat-caption" class="caption-frame">
<p>Figure: <a href="https://www.amazon.co.uk/dp/B077Y95D6V/">The Mind is
Flat Nick Chater</a> relates the extent to which how we are is
determined by the data we see.</p>
</div>
</div>
<p><span class="citation" data-cites="Chater-mindisflat19">(Chater,
2019)</span></p>
<p>This perspective challenges traditional notions of a deep,
unconscious mind and raises questions about the nature of consciousness
and decision-making.</p>
<p>}</p>
<div class="figure">
<div id="behind-the-mirror-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//books/behind-the-mirror.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="behind-the-mirror-magnify" class="magnify"
onclick="magnifyFigure(&#39;behind-the-mirror&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="behind-the-mirror-caption" class="caption-frame">
<p>Figure: <a
href="https://en.wikipedia.org/wiki/Behind_the_Mirror">Behind the
Mirror</a> <span class="citation" data-cites="Lorenz-mirror77">(Lorenz,
1977)</span> introduces the notion of thinking as <em>acting in an
imagined space</em>. (see also work by Bernhard Schölkopf.</p>
</div>
</div>
<p><span class="citation" data-cites="Lorenz-mirror77">(Lorenz,
1977)</span></p>
<p>Lorenz’s work introduces the idea of thinking as acting in an
imagined space, which has implications for our understanding of
cognition and AI.</p>
<h1 id="artistic-perspectives-on-human-nature">Artistic Perspectives on
Human Nature</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/philosophy.gpp.markdown', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="elohim-creating-adam">Elohim Creating Adam</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-elohim-creating-adam.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-elohim-creating-adam.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Blake’s vision of the creation of man, known as Elohim Creating Adam,
is a strong contrast to Michelangelo’s. The faces of both God and Adam
show deep anguish. The image is closer to representations of Prometheus
receiving his punishment for sharing his knowledge of fire than to the
languid ecstasy we see in Michelangelo’s representation.</p>
<div class="figure">
<div id="elohim-creating-adam-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//art/blake-elohim-creating-adam.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="elohim-creating-adam-magnify" class="magnify"
onclick="magnifyFigure(&#39;elohim-creating-adam&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="elohim-creating-adam-caption" class="caption-frame">
<p>Figure: William Blake’s <em>Elohim Creating Adam</em>.</p>
</div>
</div>
<p>The caption in the Tate reads:</p>
<blockquote>
<p>Elohim is a Hebrew name for God. This picture illustrates the Book of
Genesis: ‘And the Lord God formed man of the dust of the ground’. Adam
is shown growing out of the earth, a piece of which Elohim holds in his
left hand.</p>
<p>For Blake the God of the Old Testament was a false god. He believed
the Fall of Man took place not in the Garden of Eden, but at the time of
creation shown here, when man was dragged from the spiritual realm and
made material.</p>
<p>From the <a
href="https://www.tate.org.uk/art/artworks/blake-elohim-creating-adam-n05055">Tate
Britain</a></p>
</blockquote>
<p>Blake’s vision is demonstrating the frustrations we experience when
the (complex) real world doesn’t manifest in the way we’d hoped.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> Blake, William <em>Elohim Creating Adam</em> p. 121,
217–18.</p>
<p>Blake’s work provides a philosophical counterpoint to the rationalist
view of human nature, emphasizing creativity and imagination.</p>
<h1 id="the-nature-of-scientific-revolutions">The Nature of Scientific
Revolutions</h1>
<h1 id="the-structure-of-scientific-revolutions">The Structure of
Scientific Revolutions</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_books/includes/the-structure-of-scientific-revolutions.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-structure-of-scientific-revolutions.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="the-structure-of-scientific-revolutions-figure"
class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//books/structure-of-scientific-revolutions.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-structure-of-scientific-revolutions-magnify"
class="magnify"
onclick="magnifyFigure(&#39;the-structure-of-scientific-revolutions&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-structure-of-scientific-revolutions-caption"
class="caption-frame">
<p>Figure: <a
href="https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions">The
Structure of Scientific Revolutions by Thomas S. Kuhn</a> suggests
scientific paradigms are recorded in books.</p>
</div>
</div>
<p>Kuhn was a historian of science and a philosopher who suggested that
the sociology of science has two principal components to it. His idea is
that “normal science” operates within a paradigm That paradigm is
defined by books which encode our best understanding. An example of a
paradigm is Newtonian mechanics, or another example would be the
geocentric view of the Universe. Within a paradigm normal science
proceeds by scientists solving the “puzzles” that paradigm sets. A
paradigm shift is when the paradigm changes, for example the Corpernican
revolution or the introduction of relativity.</p>
<p>The notion of a paradigm shift has also entered common parlance, this
reflects the idea that wider human knowledge is also shared and stored,
less ormally than scientific knowledge, but still with a dependence on
our information infrastructure.</p>
<p>The digital computer has brought a fundamental change in the nature
of that information infrastructure. By moving information faster the
modern information infrastructure is dominated not by the book, but by
the machine. This brings challenges for managing and controlling this
information infrastructure.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> Kuhn, Thomas: <em>The Structure of Scientific
Revolutions</em> p. 295–299.</p>
<p>Kuhn’s work raises important philosophical questions about the nature
of scientific progress and how paradigms shift, which is particularly
relevant in the rapidly evolving field of AI.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> Kuhn, Thomas: <em>The Structure of Scientific
Revolutions</em> p. 295–299.</p>
<h1 id="the-philosophy-of-information">The Philosophy of
Information</h1>
<h2 id="maxwells-demon">Maxwell’s Demon</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_physics/includes/maxwells-demon-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/maxwells-demon-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="maxwells-demon-figure" class="figure-frame">
<object class data="https://mlatcl.github.io/atomichuman/../slides/diagrams//physics/maxwells-demon.svg" width="100%" style=" ">
</object>
</div>
<div id="maxwells-demon-magnify" class="magnify"
onclick="magnifyFigure(&#39;maxwells-demon&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="maxwells-demon-caption" class="caption-frame">
<p>Figure: Maxwell’s demon opens and closes a door which allows fast
particles to pass from left to right and slow particles to pass from
right to left. This makes the left hand side colder than the right.</p>
</div>
</div>
<div class="figure">
<div id="maxwells-demon-figure" class="figure-frame">
<div>
<div style="width:68%;float:left">
<canvas id="maxwell-canvas" width="700" height="500" style="border:1px solid black;display:inline;text-align:left">
</canvas>
</div>
<div style="width:28%;float:right;margin:auto">
<div style="float:right;width:100%;margin:auto">
Entropy:
<output id="maxwell-entropy">
</output>
</div>
<div id="maxwell-histogram-canvas"
style="width:300px;height:250px;display:inline-block;text-align:right;margin:auto">

</div>
</div>
</div>
<div>
<button id="maxwell-newball" style="text-align:right">
New Ball
</button>
<button id="maxwell-pause" style="text-align:right">
Pause
</button>
<button id="maxwell-skip" style="text-align:right">
Skip 1000s
</button>
<button id="maxwell-histogram" style="text-align:right">
Histogram
</button>
</div>
<script src="https://inverseprobability.com/talks/scripts//ballworld/ballworld.js"></script>
<script src="https://inverseprobability.com/talks/scripts//ballworld/maxwell.js"></script>
</div>
<div id="maxwells-demon-magnify" class="magnify"
onclick="magnifyFigure(&#39;maxwells-demon&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="maxwells-demon-caption" class="caption-frame">
<p>Figure: Maxwell’s Demon. The demon decides balls are either cold
(blue) or hot (red) according to their velocity. Balls are allowed to
pass the green membrane from right to left only if they are cold, and
from left to right, only if they are hot.</p>
</div>
</div>
<p>Maxwell’s Demon thought experiment raises profound questions about
the nature of information, entropy, and the limits of knowledge.</p>
<h1
id="human-machine-interaction-philosophical-implications">Human-Machine
Interaction: Philosophical Implications</h1>
<h2 id="computer-conversations">Computer Conversations</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="anne-computer-conversation-6-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//anne-computer-conversation006.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-6-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-computer-conversation-6&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-computer-conversation-6-caption" class="caption-frame">
<p>Figure: Conversation relies on internal models of other
individuals.</p>
</div>
</div>
<div class="figure">
<div id="anne-computer-conversation-8-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//anne-computer-conversation007.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-computer-conversation-8-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-computer-conversation-8&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-computer-conversation-8-caption" class="caption-frame">
<p>Figure: Misunderstanding of context and who we are talking to leads
to arguments.</p>
</div>
</div>
<p>Similarly, we find it difficult to comprehend how computers are
making decisions. Because they do so with more data than we can possibly
imagine.</p>
<p>In many respects, this is not a problem, it’s a good thing. Computers
and us are good at different things. But when we interact with a
computer, when it acts in a different way to us, we need to remember
why.</p>
<p>Just as the first step to getting along with other humans is
understanding other humans, so it needs to be with getting along with
our computers.</p>
<p>Embodiment factors explain why, at the same time, computers are so
impressive in simulating our weather, but so poor at predicting our
moods. Our complexity is greater than that of our weather, and each of
us is tuned to read and respond to one another.</p>
<p>Their intelligence is different. It is based on very large quantities
of data that we cannot absorb. Our computers don’t have a complex
internal model of who we are. They don’t understand the human condition.
They are not tuned to respond to us as we are to each other.</p>
<p>Embodiment factors encapsulate a profound thing about the nature of
humans. Our locked in intelligence means that we are striving to
communicate, so we put a lot of thought into what we’re communicating
with. And if we’re communicating with something complex, we naturally
anthropomorphize them.</p>
<p>We give our dogs, our cats, and our cars human motivations. We do the
same with our computers. We anthropomorphize them. We assume that they
have the same objectives as us and the same constraints. They don’t.</p>
<p>This means, that when we worry about artificial intelligence, we
worry about the wrong things. We fear computers that behave like more
powerful versions of ourselves that will struggle to outcompete us.</p>
<p>In reality, the challenge is that our computers cannot be human
enough. They cannot understand us with the depth we understand one
another. They drop below our cognitive radar and operate outside our
mental models.</p>
<p>The real danger is that computers don’t anthropomorphize. They’ll
make decisions in isolation from us without our supervision because they
can’t communicate truly and deeply with us.</p>
<p>This comparison between human and computer communication raises
philosophical questions about the nature of understanding and the
potential for true human-machine interaction.</p>
<h1 id="the-ethics-of-ai">The Ethics of AI</h1>
<h2 id="p-fairness-and-n-fairness"><span
class="math inline">\(p\)</span>-Fairness and <span
class="math inline">\(n\)</span>-Fairness</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/p-n-fairness.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/p-n-fairness.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="n-p-fairness-figure" class="figure-frame">
<object class data="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/n-p-fairness.svg" width="80%" style=" ">
</object>
</div>
<div id="n-p-fairness-magnify" class="magnify"
onclick="magnifyFigure(&#39;n-p-fairness&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="n-p-fairness-caption" class="caption-frame">
<p>Figure: We seem to have two different aspects to fairness, which in
practice can be in tension.</p>
</div>
</div>
<p>We’ve outlined <span class="math inline">\(n\)</span>-fairness and
<span class="math inline">\(p\)</span>-fairness. By <span
class="math inline">\(n\)</span>-fairness we mean the sort of
considerations that are associated with <em>substantive</em> equality of
opportunity vs <em>formal</em> equality of opportunity. Formal equality
of community is related to <span
class="math inline">\(p\)</span>-fairness. This is sometimes called
procedural fairness and we might think of it as a <em>performative</em>
form of fairness. It’s about clarity of rules, for example as applied in
sport. <span class="math inline">\(n\)</span>-Fairness is more nuanced.
It’s a reflection of society’s normative judgment about how individuals
may have been disadvantaged, e.g. due to their upbringing.</p>
<p>The important point here is that these forms of fairness are in
tension. Good procedural fairness needs to be clear and understandable.
It should be clear to everyone what the rules are, they shouldn’t be
obscured by jargon or overly subtle concepts. <span
class="math inline">\(p\)</span>-Fairness should not be easily
undermined by adversaries, it should be difficult to “cheat” good <span
class="math inline">\(p\)</span>-fairness. However, <span
class="math inline">\(n\)</span>-fairness requires nuance, understanding
of the human condition, where we came from and how different individuals
in our society have been advantaged or disadvantaged in their upbringing
and their access to opportunity.</p>
<p>Pure <span class="math inline">\(n\)</span>-fairness and pure <span
class="math inline">\(p\)</span>-fairness both have the feeling of
dystopias. In practice, any decision making system needs to balance the
two. The correct point of operation will depend on the context of the
decision. Consider fair rules of a game of football, against fair
distribution of social benefit. It is unlikely that there is ever an
objectively correct balance between the two for any given context.
Different individuals will favour <span class="math inline">\(p\)</span>
vs <span class="math inline">\(n\)</span> according to their personal
values.</p>
<p>Given the tension between the two forms of fairness, with <span
class="math inline">\(p\)</span> fairness requiring simple rules that
are understandable by all, and <span class="math inline">\(n\)</span>
fairness requiring nuance and subtlety, how do we resolve this tension
in practice?</p>
<p>Normally in human systems, significant decisions involve trained
professionals. For example, judges, or accountants or doctors.</p>
<p>Training a professional involves lifting their “reflexive” response
to a situation with “reflective” thinking about the consequences of
their decision that rely not just on the professional’s expertise, but
also their knowledge of what it is to be a human.</p>
<p>This <em>marvellous</em> resolution exploits the fact that while
humans are increadibly complicated nuanced entities, other humans have
an intuitive ability to understand their motivations and values. So the
human is a complex entity that seems simple to other humans.</p>
<p>This framework for considering fairness in AI systems raises
important philosophical questions about justice, equality, and the
nature of ethical decision-making.</p>
<h1 id="trust-and-ai">Trust and AI</h1>
<h2 id="a-question-of-trust">A Question of Trust</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_books/includes/a-question-of-trust.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/a-question-of-trust.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>In Baroness Onora O’Neill’s Reeith Lectures from 2002, she raises the
challenge of trust. There are many aspects to her arcuments, but one of
the key points she makes is that we cannot trust without the notion of
duty. O’Neill is bemoaning the substitution of duty with process. The
idea is that processes and transparency are supposed to hold us to
account by measuring outcomes. But these processes themselves overwhelm
decision makers and undermine their professional duty to deliver the
right outcome.</p>
<div class="figure">
<div id="a-question-of-trust-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//books/a-question-of-trust.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="a-question-of-trust-magnify" class="magnify"
onclick="magnifyFigure(&#39;a-question-of-trust&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="a-question-of-trust-caption" class="caption-frame">
<p>Figure: <a href="https://www.bbc.co.uk/programmes/p00gpzfq">A
Question of Trust by Onora O’Neil</a> which examines the nature of trust
and its role in society.</p>
</div>
</div>
<blockquote>
<p>Again Univesities are to treat each applicant fairly on the basis of
ability and promise, but they are supposed also to admit a socially more
representative intake.</p>
<p>There’s no guarantee that the process meets the target.</p>
<p>Onora O’Neill <em>A Question of Trust: Called to Account</em> Reith
Lectures 2002 <span class="citation" data-cites="ONeill-trust02">O’Neill
(2002)</span>]</p>
</blockquote>
<p>O’Neill is speaking in 2002, in the early days of the internet and
before social media. Much of her thoughts are even more relevant for
today than they were when she spoke. This is because the increased
availability of information and machine driven decision-making makes the
mistaken premise, that process is an adequate substitute for duty, more
apparently plausible. But this undermines what O’Neill calls
“intelligent accountability”, which is not accounting by the numbers,
but through professional education and institutional safeguards.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> O’Neill, Baroness Onora: ‘A question of trust’ lecture
series (2002) p. 352, 363.</p>
<p>O’Neill’s work raises important philosophical questions about the
nature of trust in the age of AI and how we can maintain “intelligent
accountability” in complex systems.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> O’Neill, Baroness Onora: ‘A question of trust’ lecture
series (2002) p. 352, 363.</p>
<h1 id="the-future-of-human-intelligence">The Future of Human
Intelligence</h1>
<h2 id="the-atomic-human">The Atomic Human</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-atomic-eye.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-atomic-eye.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="the-atomic-eye-figure" class="figure-frame">
<object class data="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/atomic-eye.svg" width="45%" style=" ">
</object>
</div>
<div id="the-atomic-eye-magnify" class="magnify"
onclick="magnifyFigure(&#39;the-atomic-eye&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-atomic-eye-caption" class="caption-frame">
<p>Figure: The Atomic Eye, by slicing away aspects of the human that we
used to believe to be unique to us, but are now the preserve of the
machine, we learn something about what it means to be human.</p>
</div>
</div>
<p>The development of what some are calling <em>intelligence</em> in
machines, raises questions around what machine intelligence means for
our intelligence. The idea of the atomic human is derived from
Democritus’s atomism.</p>
<p>In the fifth century <span class="smallcaps">bce</span> the Greek
philosopher Democritus posed a similar question about our physical
universe. He imagined cutting physical matter into pieces in a repeated
process: cutting a piece, then taking one of the cut pieces and cutting
it again so that each time it becomes smaller and smaller. Democritus
believed this process had to stop somewhere, that we would be left with
an indivisible piece. The Greek word for indivisible is <em>atom</em>,
and so this theory was called <em>atomism</em>. This book considers this
question, but in a different domain, asking: As the machine slices away
portions of human capabilities, are we left with a kernel of humanity,
an indivisible piece that can no longer be divided into parts? Or does
the human disappear altogether? If we are left with something, then that
uncuttable piece, a form of atomic human, would tell us something about
our human spirit.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> atomic human, the p. 13.</p>
<p>This concept of the “atomic human” raises philosophical questions
about the essential nature of human intelligence and how it might be
affected by advances in AI.</p>
<h1 id="ai-and-the-evolution-of-knowledge-representation">AI and the
Evolution of Knowledge Representation</h1>
<h2 id="the-moniac">The MONIAC</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><a href="https://en.wikipedia.org/wiki/MONIAC">The MONIAC</a> was an
analogue computer designed to simulate the UK economy. Analogue
comptuers work through analogy, the analogy in the MONIAC is that both
money and water flow. The MONIAC exploits this through a system of
tanks, pipes, valves and floats that represent the flow of money through
the UK economy. Water flowed from the treasury tank at the top of the
model to other tanks representing government spending, such as health
and education. The machine was initially designed for teaching support
but was also found to be a useful economic simulator. Several were built
and today you can see the original at Leeds Business School, there is
also one in the London Science Museum and one <a
href="https://www.econ.cam.ac.uk/economics-alumni/drip-down-economics-phillips-machine">in
the Unisversity of Cambridge’s economics faculty</a>.</p>
<div class="figure">
<div id="the-moniac-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//simulation/Phillips_and_MONIAC_LSE.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-moniac-magnify" class="magnify"
onclick="magnifyFigure(&#39;the-moniac&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-moniac-caption" class="caption-frame">
<p>Figure: Bill Phillips and his MONIAC (completed in 1949). The machine
is an analogue computer designed to simulate the workings of the UK
economy.</p>
</div>
</div>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> MONIAC p. 232-233, 266, 343.</p>
<h2 id="donald-mackay">Donald MacKay</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/donald-mackay-brain.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/donald-mackay-brain.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="donald-maccrimmon-mackay-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//people/DonaldMacKay1952.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="donald-maccrimmon-mackay-magnify" class="magnify"
onclick="magnifyFigure(&#39;donald-maccrimmon-mackay&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="donald-maccrimmon-mackay-caption" class="caption-frame">
<p>Figure: Donald M. MacKay (1922-1987), a physicist who was an early
member of the cybernetics community and member of the Ratio Club.</p>
</div>
</div>
<p>Donald MacKay was a physicist who worked on naval gun targetting
during the second world war. The challenge with gun targetting for ships
is that both the target and the gun platform are moving. The challenge
was tackled using analogue computers, for example in the US the <a
href="https://en.wikipedia.org/wiki/Mark_I_Fire_Control_Computer">Mark I
fire control computer</a> which was a mechanical computer. MacKay worked
on radar systems for gun laying, here the velocity and distance of the
target could be assessed through radar and an mechanical electrical
analogue computer.</p>
<h2 id="fire-control-systems">Fire Control Systems</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/fire-control-systems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/fire-control-systems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Naval gunnery systems deal with targeting guns while taking into
account movement of ships. The Royal Navy’s Gunnery Pocket Book <span
class="citation" data-cites="Admiralty-gunnery45">(The Admiralty,
1945)</span> gives details of one system for gun laying.</p>
<p>Like many challenges we face today, in the second world war, fire
control was handled by a hybrid system of humans and computers. This
means deploying human beings for the tasks that they can manage, and
machines for the tasks that are better performed by a machine. This
leads to a division of labour between the machine and the human that can
still be found in our modern digital ecosystems.</p>
<div class="figure">
<div id="low-angle-fire-control-team-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/low-angle-fire-control-team.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="low-angle-fire-control-team-magnify" class="magnify"
onclick="magnifyFigure(&#39;low-angle-fire-control-team&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="low-angle-fire-control-team-caption" class="caption-frame">
<p>Figure: The fire control computer set at the centre of a system of
observation and tracking <span class="citation"
data-cites="Admiralty-gunnery45">(The Admiralty, 1945)</span>.</p>
</div>
</div>
<p>As analogue computers, fire control computers from the second world
war would contain components that directly represented the different
variables that were important in the problem to be solved, such as the
inclination between two ships.</p>
<div class="figure">
<div id="the-measurement-of-inclination-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/the-measurement-of-inclination.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-measurement-of-inclination-magnify" class="magnify"
onclick="magnifyFigure(&#39;the-measurement-of-inclination&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-measurement-of-inclination-caption" class="caption-frame">
<p>Figure: Measuring inclination between two ships <span
class="citation" data-cites="Admiralty-gunnery45">(The Admiralty,
1945)</span>. Sophisticated fire control computers allowed the ship to
continue to fire while under maneuvers.</p>
</div>
</div>
<p>The fire control systems were electro-mechanical analogue computers
that represented the “state variables” of interest, such as inclination
and ship speed with gears and cams within the machine.</p>
<div class="figure">
<div id="typical-modern-fire-control-table-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/typical-modern-fire-control-table.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="typical-modern-fire-control-table-magnify" class="magnify"
onclick="magnifyFigure(&#39;typical-modern-fire-control-table&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="typical-modern-fire-control-table-caption"
class="caption-frame">
<p>Figure: A second world war gun computer’s control table <span
class="citation" data-cites="Admiralty-gunnery45">(The Admiralty,
1945)</span>.</p>
</div>
</div>
<p>For more details on fire control computers, you can watch a 1953 film
on the the US the <a
href="https://en.wikipedia.org/wiki/Mark_I_Fire_Control_Computer">Mark
IA fire control computer</a> from Periscope Film.</p>
<div class="figure">
<div id="us-navy-training-film-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/gwf5mAlI7Ug?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="us-navy-training-film-magnify" class="magnify"
onclick="magnifyFigure(&#39;us-navy-training-film&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="us-navy-training-film-caption" class="caption-frame">
<p>Figure: U.S. Navy training film MN-6783a. Basic Mechanisms of Fire
Control Computers. Mechanical Computer Instructional Film 27794 (1953)
for the Mk 1A Fire Control Computer.</p>
</div>
</div>
<h2 id="behind-the-eye">Behind the Eye</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_books/includes/behind-the-eye.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/behind-the-eye.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="behind-the-eye-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//books/behind-the-eye.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="behind-the-eye-magnify" class="magnify"
onclick="magnifyFigure(&#39;behind-the-eye&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="behind-the-eye-caption" class="caption-frame">
<p>Figure: <a
href="https://www.amazon.co.uk/Behind-Eye-Gifford-Lectures-MACKAY/dp/0631173323">Behind
the Eye</a> <span class="citation" data-cites="Mackay-behind91">(MacKay,
1991)</span> summarises MacKay’s Gifford Lectures, where MacKay uses the
operation of the eye as a window on the operation of the brain.</p>
</div>
</div>
<p>Donald MacKay was at King’s College for his PhD. He was just down the
road from Bill Phillips at LSE who was building the MONIAC. He was part
of the Ratio Club. A group of early career scientists who were
interested in communication and control in animals and humans, or more
specifically they were interested in computers and brains. The were part
of an international movement known as cybernetics.</p>
<p>Donald MacKay wrote of the influence that his own work on radar had
on his interest in the brain.</p>
<blockquote>
<p>… during the war I had worked on the theory of automated and
electronic computing and on the theory of information, all of which are
highly relevant to such things as automatic pilots and automatic gun
direction. I found myself grappling with problems in the design of
artificial sense organs for naval gun-directors and with the principles
on which electronic circuits could be used to simulate situations in the
external world so as to provide goal-directed guidance for ships,
aircraft, missiles and the like.</p>
</blockquote>
<blockquote>
<p>Later in the 1940’s, when I was doing my Ph.D. work, there was much
talk of the brain as a computer and of the early digital computers that
were just making the headlines as “electronic brains.” As an analogue
computer man I felt strongly convinced that the brain, whatever it was,
was not a digital computer. I didn’t think it was an analogue computer
either in the conventional sense.</p>
</blockquote>
<blockquote>
<p>But this naturally rubbed under my skin the question: well, if it is
not either of these, what kind of system is it? Is there any way of
following through the kind of analysis that is appropriate to their
artificial automata so as to understand better the kind of system the
human brain is? That was the beginning of my slippery slope into brain
research.</p>
<p><em>Behind the Eye</em> pg 40. Edited version of the 1986 Gifford
Lectures given by Donald M. MacKay and edited by Valerie MacKay</p>
</blockquote>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> MacKay, Donald, <em>Behind the Eye</em> p. 268-270,
316.</p>
<p>Importantly, MacKay distinguishes between the <em>analogue</em>
computer and the <em>digital</em> computer. As he mentions, his
experience was with analogue machines. An analogue machine is
<em>literally</em> an analogue. The radar systems that Wiener and MacKay
both worked on were made up of electronic components such as resistors,
capacitors, inductors and/or mechanical components such as cams and
gears. Together these components could represent a physical system, such
as an anti-aircraft gun and a plane. The design of the analogue computer
required the engineer to simulate the real world in analogue
electronics, using dualities that exist between e.g. mechanical circuits
(mass, spring, damper) and electronic circuits (inductor, resistor,
capacitor). The analogy between mass and a damper, between spring and a
resistor and between capacitor and a damper works because the underlying
mathematics is approximated with the same linear system: a second order
differential equation. This mathematical analogy allowed the designer to
map from the real world, through mathematics, to a virtual world where
the components reflected the real world through analogy.</p>
<h2 id="human-analogue-machine">Human Analogue Machine</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/human-analogue-machines-short.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/human-analogue-machines-short.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The machine learning systems we have built today that can reconstruct
human text, or human classification of images, necessarily must have
some aspects to them that are analagous to our understanding. As MacKay
suggests the brain is neither a digital or an analogue computer, and the
same can be said of the modern neural network systems that are being
tagged as “artificial intelligence”.</p>
<p>I believe a better term for them is “human-analogue machines”,
because what we have built is not a system that can make intelligent
decisions from first principles (a rational approach) but one that
observes how humans have made decisions through our data and
reconstructs that process. Machine learning is more empiricist than
rational, but now we n empirical approach that distils our evolved
intelligence.</p>
<div class="figure">
<div id="human-analogue-machine-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/human-analogue-machine.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="human-analogue-machine-magnify" class="magnify"
onclick="magnifyFigure(&#39;human-analogue-machine&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="human-analogue-machine-caption" class="caption-frame">
<p>Figure: The human analogue machine creates a feature space which is
analagous to that we use to reason, one way of doing this is to have a
machine attempt to compress all human generated text in an
auto-regressive manner.</p>
</div>
</div>
<h3 id="heider-and-simmel-1944">Heider and Simmel (1944)</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/heider-simmel.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/heider-simmel.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="heider-simmel-shapes-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/8FIEZXMUM2I?start=7" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="heider-simmel-shapes-magnify" class="magnify"
onclick="magnifyFigure(&#39;heider-simmel-shapes&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="heider-simmel-shapes-caption" class="caption-frame">
<p>Figure: Fritz Heider and Marianne Simmel’s video of shapes from <span
class="citation" data-cites="Heider-experimental44">Heider and Simmel
(1944)</span>.</p>
</div>
</div>
<p><a href="https://en.wikipedia.org/wiki/Fritz_Heider">Fritz Heider</a>
and <a href="https://en.wikipedia.org/wiki/Marianne_Simmel">Marianne
Simmel</a>’s experiments with animated shapes from 1944 <span
class="citation" data-cites="Heider-experimental44">(Heider and Simmel,
1944)</span>. Our interpretation of these objects as showing motives and
even emotion is a combination of our desire for narrative, a need for
understanding of each other, and our ability to empathize. At one level,
these are crudely drawn objects, but in another way, the animator has
communicated a story through simple facets such as their relative
motions, their sizes and their actions. We apply our psychological
representations to these faceless shapes to interpret their actions.</p>
<p>See also a recent review paper on Human Cooperation by <span
class="citation" data-cites="Joseph-origins21">Henrich and Muthukrishna
(2021)</span>.</p>
<p>The perils of developing this capability include counterfeit people,
a notion that the philosopher <a
href="https://www.theatlantic.com/technology/archive/2023/05/problem-counterfeit-people/674075/">Daniel
Dennett has described in <em>The Atlantic</em></a>. This is where
computers can represent themselves as human and fool people into doing
things on that basis.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> human-analogue machine p. 343–5, 346–7, 358–9, 365–8.</p>
<h2 id="llm-conversations">LLM Conversations</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-llm.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-llm.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="anne-llm-conversation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/anne-llm-conversation.svg" width="80%" style=" ">
</object>
</div>
<div id="anne-llm-conversation-magnify" class="magnify"
onclick="magnifyFigure(&#39;anne-llm-conversation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="anne-llm-conversation-caption" class="caption-frame">
<p>Figure: The focus so far has been on reducing uncertainty to a few
representative values and sharing numbers with human beings. We forget
that most people can be confused by basic probabilities for example the
prosecutor’s fallacy.</p>
</div>
</div>
<div class="figure">
<div id="ai-for-data-analytics-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/0sJjdxn5kcI?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="ai-for-data-analytics-magnify" class="magnify"
onclick="magnifyFigure(&#39;ai-for-data-analytics&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ai-for-data-analytics-caption" class="caption-frame">
<p>Figure: The Inner Monologue paper suggests using LLMs for robotic
planning <span class="citation" data-cites="Huang-inner22">(Huang et
al., 2023)</span>.</p>
</div>
</div>
<p>By interacting directly with machines that have an understanding of
human cultural context, it should be possible to share the nature of
uncertainty in the same way humans do. See for example the paper <a
href="https://innermonologue.github.io/">Inner Monologue: Embodied
Reasoning through Planning</a> <span class="citation"
data-cites="Huang-inner22">Huang et al. (2023)</span>.</p>
<h2 id="intellectual-debt">Intellectual Debt</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-blog-post.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-blog-post.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="intellectual-debt-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/2020-02-12-intellectual-debt.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="intellectual-debt-magnify" class="magnify"
onclick="magnifyFigure(&#39;intellectual-debt&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="intellectual-debt-caption" class="caption-frame">
<p>Figure: Jonathan Zittrain’s term to describe the challenges of
explanation that come with AI is Intellectual Debt.</p>
</div>
</div>
<p>In the context of machine learning and complex systems, Jonathan
Zittrain has coined the term <a
href="https://medium.com/berkman-klein-center/from-technical-debt-to-intellectual-debt-in-ai-e05ac56a502c">“Intellectual
Debt”</a> to describe the challenge of understanding what you’ve
created. In <a
href="https://mlatcl.github.io/projects/data-oriented-architectures-for-ai-based-systems.html">the
ML@CL group we’ve been foucssing on developing the notion of a
<em>data-oriented architecture</em></a> to deal with intellectual debt
<span class="citation" data-cites="Cabrera-realworld23">(Cabrera et al.,
2023)</span>.</p>
<p>Zittrain points out the challenge around the lack of interpretability
of individual ML models as the origin of intellectual debt. In machine
learning I refer to work in this area as fairness, interpretability and
transparency or FIT models. To an extent I agree with Zittrain, but if
we understand the context and purpose of the decision making, I believe
this is readily put right by the correct monitoring and retraining
regime around the model. A concept I refer to as “progression testing”.
Indeed, the best teams do this at the moment, and their failure to do it
feels more of a matter of technical debt rather than intellectual,
because arguably it is a maintenance task rather than an explanation
task. After all, we have good statistical tools for interpreting
individual models and decisions when we have the context. We can
linearise around the operating point, we can perform counterfactual
tests on the model. We can build empirical validation sets that explore
fairness or accuracy of the model.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> intellectual debt p. 84, 85, 349, 365.</p>
<p>But if we can avoid the pitfalls of counterfeit people, this also
offers us an opportunity to <em>psychologically represent</em> <span
class="citation" data-cites="Heider:interpersonal58">(Heider,
1958)</span> the machine in a manner where humans can communicate
without special training. This in turn offers the opportunity to
overcome the challenge of <em>intellectual debt</em>.</p>
<p>Despite the lack of interpretability of machine learning models, they
allow us access to what the machine is doing in a way that bypasses many
of the traditional techniques developed in statistics. But understanding
this new route for access is a major new challenge.</p>
<h2 id="ham">HAM</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Human-Analogue Machine or HAM therefore provides a route through
which we could better understand our world through improving the way we
interact with machines.</p>
<div class="figure">
<div id="new-flow-of-information-4-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//data-science/new-flow-of-information004.svg" width="70%" style=" ">
</object>
</div>
<div id="new-flow-of-information-4-magnify" class="magnify"
onclick="magnifyFigure(&#39;new-flow-of-information-4&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="new-flow-of-information-4-caption" class="caption-frame">
<p>Figure: The trinity of human, data, and computer, and highlights the
modern phenomenon. The communication channel between computer and data
now has an extremely high bandwidth. The channel between human and
computer and the channel between data and human is narrow. New direction
of information flow, information is reaching us mediated by the
computer. The focus on classical statistics reflected the importance of
the direct communication between human and data. The modern challenges
of data science emerge when that relationship is being mediated by the
machine.</p>
</div>
</div>
<p>The HAM can provide an interface between the digital computer and the
human allowing humans to work closely with computers regardless of their
understandin gf the more technical parts of software engineering.</p>
<div class="figure">
<div id="new-flow-of-information-ham-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//data-science/new-flow-of-information-ham.svg" width="70%" style=" ">
</object>
</div>
<div id="new-flow-of-information-ham-magnify" class="magnify"
onclick="magnifyFigure(&#39;new-flow-of-information-ham&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="new-flow-of-information-ham-caption" class="caption-frame">
<p>Figure: The HAM now sits between us and the traditional digital
computer.</p>
</div>
</div>
<p>Of course this route provides new routes for manipulation, new ways
in which the machine can undermine our autonomy or exploit our cognitive
foibles. The major challenge we face is steering between these worlds
where we gain the advantage of the computer’s bandwidth without
undermining our culture and individual autonomy.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> human-analogue machine (HAMs) p. 343-347, 359-359,
365-368.</p>
<h2 id="networked-interactions">Networked Interactions</h2>
<p>Our modern society intertwines the machine with human interactions.
The key question is who has control over these interfaces between humans
and machines.</p>
<div class="figure">
<div id="human-computers-interacting-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/atomichuman/../slides/diagrams//ai/human-computers-interacting.svg" width="80%" style=" ">
</object>
</div>
<div id="human-computers-interacting-magnify" class="magnify"
onclick="magnifyFigure(&#39;human-computers-interacting&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="human-computers-interacting-caption" class="caption-frame">
<p>Figure: Humans and computers interacting should be a major focus of
our research and engineering efforts.</p>
</div>
</div>
<p>So the real challenge that we face for society is understanding which
systemic interventions will encourage the right interactions between the
humans and the machine at all of these interfaces.</p>
<p>The concept of human analogue machines raises philosophical questions
about the nature of knowledge representation and the potential for
machines to truly understand human concepts.</p>
<p>See <span class="citation" data-cites="Lawrence-atomic24">Lawrence
(2024)</span> human-analogue machine p. 343–5, 346–7, 358–9, 365–8.</p>
<h1 id="the-philosophical-implications-of-uncertainty">The Philosophical
Implications of Uncertainty</h1>
<h2 id="richard-feynmann-on-doubt">Richard Feynmann on Doubt</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_physics/includes/richard-feynmann-doubt.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/richard-feynmann-doubt.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<blockquote>
<p>One thing is I can live with is doubt, and uncertainty and not
knowing. I think it’s much more interesting to live with not knowing
than to have an answer that might be wrong.</p>
<p>Richard P. Feynmann in the <em>The Pleasure of Finding Things
Out</em> 1981.</p>
</blockquote>
<p>Feynman’s perspective on doubt and uncertainty challenges traditional
philosophical notions of knowledge and truth, and has implications for
how we approach AI and scientific understanding.</p>
<h1 id="the-nature-of-explanation-in-the-age-of-ai">The Nature of
Explanation in the Age of AI</h1>
<h2 id="autoai-fit-models-to-fit-systems">AutoAI: FIT Models to FIT
Systems</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-models-to-fit-systems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/fit-models-to-fit-systems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The idea of AutoAI is to combine the streaming algebra we obtain from
the data oriented architecture (we can think of it as a ‘tube map for
data flows’) with monitoring techniques both from machine learning,
classical statistics and softare verification for ensuring that the
system is performing as designed and/or alerting us to when our
assumptions about the system are invalidated.</p>
<p>We can already deploy classical statistical approaches for
e.g. outlier detection, or use proofs from category theory to
demonstrate that a particular decision is not based on a protected
characteristic.</p>
<p>The additional aim would be to use techniques from uncertainty
quantification and statistical emulation to provide more
interpretability to those decisions.</p>
<p>This domain has been called FAT modelling in machine learning, but I
prefer the acronym FIT for fairness, interpretability and
transparency.</p>
<p>AutoAI makes us realise that AutoML isn’t sufficient for improving
the performance of the system, because it works on a componentwise
basis. Similarly, FIT machine learning models are not sufficient. We
need to move from FIT models to FIT systems.</p>
<p>This transition from FIT models to FIT systems raises philosophical
questions about the nature of explanation and understanding in complex
AI systems.</p>
<h1
id="conclusion-the-atomic-human-in-philosophical-context">Conclusion:
The Atomic Human in Philosophical Context</h1>
<p>As we conclude this philosophical journey, we see how AI challenges
and reshapes our understanding of intelligence, consciousness,
knowledge, and what it means to be human. The concept of the “atomic
human” emerges as a philosophical response to these challenges,
emphasizing the unique aspects of human intelligence that persist even
as AI capabilities expand.</p>
<p>The philosophical questions raised by AI - about the nature of mind,
the limits of knowledge, the ethics of artificial systems, and the
future of human intelligence - will continue to be central to our
understanding of both AI and ourselves. As we move forward, these
philosophical considerations will be crucial in guiding the development
and deployment of AI in ways that respect and enhance human values and
capabilities.</p>
<p>In our next lecture, we’ll explore how these philosophical
considerations translate into practical governance challenges in the age
of AI.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to
check the following resources.</p>
<ul>
<li>book: <a
href="https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248">The
Atomic Human</a></li>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking
Machines</a></li>
<li>newspaper: <a
href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile
Page</a></li>
<li>blog: <a
href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Hawking-history88" class="csl-entry" role="listitem">
A brief history of time, 1988. Bantam Dell Publishing Group, London.
</div>
<div id="ref-Ananthanarayanan-cat09" class="csl-entry" role="listitem">
Ananthanarayanan, R., Esser, S.K., Simon, H.D., Modha, D.S., 2009. The
cat is out of the bag: Cortical simulations with <span
class="math inline">\(10^9\)</span> neurons, <span
class="math inline">\(10^{13}\)</span> synapses, in: Proceedings of the
Conference on High Performance Computing Networking, Storage and
Analysis - SC ’09. <a
href="https://doi.org/10.1145/1654059.1654124">https://doi.org/10.1145/1654059.1654124</a>
</div>
<div id="ref-Cabrera-realworld23" class="csl-entry" role="listitem">
Cabrera, C., Paleyes, A., Thodoroff, P., Lawrence, N.D., 2023. <a
href="https://arxiv.org/abs/2302.04810">Real-world machine learning
systems: A survey from a data-oriented architecture perspective</a>.
</div>
<div id="ref-Chater-mindisflat19" class="csl-entry" role="listitem">
Chater, N., 2019. The mind is flat. Penguin.
</div>
<div id="ref-Heider:interpersonal58" class="csl-entry" role="listitem">
Heider, F., 1958. The psychology of interpersonal relations. John Wiley.
</div>
<div id="ref-Heider-experimental44" class="csl-entry" role="listitem">
Heider, F., Simmel, M., 1944. An experimental study of apparent
behavior. The American Journal of Psychology 57, 243–259. <a
href="https://doi.org/10.2307/1416950">https://doi.org/10.2307/1416950</a>
</div>
<div id="ref-Joseph-origins21" class="csl-entry" role="listitem">
Henrich, J., Muthukrishna, M., 2021. The origins and psychology of human
cooperation. Annual Review of Psychology 72, 207–240. <a
href="https://doi.org/10.1146/annurev-psych-081920-042106">https://doi.org/10.1146/annurev-psych-081920-042106</a>
</div>
<div id="ref-Huang-inner22" class="csl-entry" role="listitem">
Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence, P., Zeng,
A., Tompson, J., Mordatch, I., Chebotar, Y., Sermanet, P., Jackson, T.,
Brown, N., Luu, L., Levine, S., Hausman, K., ichter, brian, 2023. <a
href="https://proceedings.mlr.press/v205/huang23c.html">Inner monologue:
Embodied reasoning through planning with language models</a>, in: Liu,
K., Kulic, D., Ichnowski, J. (Eds.), Proceedings of the 6th Conference
on Robot Learning, Proceedings of Machine Learning Research. PMLR, pp.
1769–1782.
</div>
<div id="ref-Laplace-essai14" class="csl-entry" role="listitem">
Laplace, P.S., 1814. Essai philosophique sur les probabilités, 2nd ed.
Courcier, Paris.
</div>
<div id="ref-Lawrence-atomic24" class="csl-entry" role="listitem">
Lawrence, N.D., 2024. <a
href="https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248">The
atomic human: Understanding ourselves in the age of AI</a>. Allen Lane.
</div>
<div id="ref-Lawrence:embodiment17" class="csl-entry" role="listitem">
Lawrence, N.D., 2017. <a href="https://arxiv.org/abs/1705.07996">Living
together: Mind and machine intelligence</a>. arXiv.
</div>
<div id="ref-Lorenz-mirror77" class="csl-entry" role="listitem">
Lorenz, K., 1977. Behind the mirror: A search for a natural history of
human knowledge. Methuen &amp; Co Ltd.
</div>
<div id="ref-Mackay-behind91" class="csl-entry" role="listitem">
MacKay, D.M., 1991. Behind the eye. Basil Blackwell.
</div>
<div id="ref-ONeill-trust02" class="csl-entry" role="listitem">
O’Neill, O., 2002. A question of trust. Cambridge University Press.
</div>
<div id="ref-Reed-information98" class="csl-entry" role="listitem">
Reed, C., Durlach, N.I., 1998. Note on information transfer rates in
human communication. Presence Teleoperators &amp; Virtual Environments
7, 509–518. <a
href="https://doi.org/10.1162/105474698565893">https://doi.org/10.1162/105474698565893</a>
</div>
<div id="ref-Admiralty-gunnery45" class="csl-entry" role="listitem">
The Admiralty, 1945. <a href="https://www.maritime.org/doc/br224/">The
gunnery pocket book, b.r. 224/45</a>.
</div>
</div>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>the challenge of understanding what information pertains
to is known as knowledge representation.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

